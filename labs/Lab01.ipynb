{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2da149-7305-480c-9b8d-516d02294aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentinel-2 Basics\n",
    "\n",
    "Goals of this lab:\n",
    "1. Use and download a tile from the open and free [Copernicus Dataspace](https://dataspace.copernicus.eu/) page\n",
    "1. Understand the structure of the downloaded data\n",
    "1. Programmatically access a specific band of the downloaded tile\n",
    "1. Visualize a Sentinel-2 band\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c8b43-3542-4c1f-b2c9-3963f33e01eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Copernicus\n",
    "\n",
    "Take a look at [browser.dataspace.copernicus.eu](https://browser.dataspace.copernicus.eu/?):\n",
    "\n",
    "![copernicus landing page](https://raw.githubusercontent.com/JonasKlotz/ipl4eo-dependencies/refs/heads/main/assets/copernicus1.png)\n",
    "\n",
    "To download a specific satellite tile, we have to:\n",
    "1. Sign up for the service (confirm the registration _e-mail_!)\n",
    "1. Query Copernicus to select tiles from target satellite with relevant parameters \n",
    "\n",
    "To select the Sentinel-2 satellite, tick the `Mission: Sentinel-2` box and use the following filter to further limit the results only to the Sentinel-2A satellite with a cloud-cover percentage of < 15%:\n",
    "\n",
    "![sentinel-2 example filter](https://raw.githubusercontent.com/JonasKlotz/ipl4eo-dependencies/refs/heads/main/assets/copernicus2.png)\n",
    "\n",
    "After providing the advanced search filters, you will get a list of various matching Sentinel-2 tiles:\n",
    "\n",
    "![example results](https://raw.githubusercontent.com/JonasKlotz/ipl4eo-dependencies/refs/heads/main/assets/copernicus3.png)\n",
    "\n",
    "If you inspect (small ⓘ icon) one of the tiles, you will see a footprint of the geographical extent of the tile, as well as a quick RGB preview image (if available) and a short textual summary:\n",
    "\n",
    "![example tile](https://raw.githubusercontent.com/JonasKlotz/ipl4eo-dependencies/refs/heads/main/assets/copernicus4.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04104f6-d5f4-4d58-9aad-46958ad9840c",
   "metadata": {},
   "source": [
    "## Downloading & inspecting the Sentinel-2 data\n",
    "\n",
    "If the selected _tile_ is available (no `offline` tag), it can be directly downloaded as a `zip` file.\n",
    "After extracting the zip file, the folder structure ([SAFE format](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/data-formats)) will look like:\n",
    "\n",
    "```\n",
    "[831M]  S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352.SAFE\n",
    "├── [ 23M]  DATASTRIP\n",
    "│   └── ...\n",
    "├── [807M]  GRANULE\n",
    "│   └── [807M]  L2A_T33UUU_A045493_20240308T101546\n",
    "│       ├── [8.5K]  AUX_DATA\n",
    "│       │   ├── [2.9K]  AUX_CAMSFO\n",
    "│       │   └── [1.6K]  AUX_ECMWFT\n",
    "│       ├── [806M]  IMG_DATA\n",
    "│       │   ├── [494M]  R10m\n",
    "│       │   │   ├── [340K]  T33UUU_20240308T100841_AOT_10m.jp2\n",
    "│       │   │   ├── [ 73M]  T33UUU_20240308T100841_B02_10m.jp2\n",
    "│       │   │   ├── [ 75M]  T33UUU_20240308T100841_B03_10m.jp2\n",
    "│       │   │   ├── [ 77M]  T33UUU_20240308T100841_B04_10m.jp2\n",
    "│       │   │   ├── [ 91M]  T33UUU_20240308T100841_B08_10m.jp2\n",
    "│       │   │   ├── [118M]  T33UUU_20240308T100841_TCI_10m.jp2\n",
    "│       │   │   └── [ 59M]  T33UUU_20240308T100841_WVP_10m.jp2\n",
    "│       │   ├── [271M]  R20m\n",
    "│       │   │   ├── [317K]  T33UUU_20240308T100841_AOT_20m.jp2\n",
    "│       │   │   ├── [ 12M]  T33UUU_20240308T100841_B01_20m.jp2\n",
    "│       │   │   ├── [ 21M]  T33UUU_20240308T100841_B02_20m.jp2\n",
    "│       │   │   ├── [ 21M]  T33UUU_20240308T100841_B03_20m.jp2\n",
    "│       │   │   ├── [ 22M]  T33UUU_20240308T100841_B04_20m.jp2\n",
    "│       │   │   ├── [ 22M]  T33UUU_20240308T100841_B05_20m.jp2\n",
    "│       │   │   ├── [ 24M]  T33UUU_20240308T100841_B06_20m.jp2\n",
    "│       │   │   ├── [ 25M]  T33UUU_20240308T100841_B07_20m.jp2\n",
    "│       │   │   ├── [ 23M]  T33UUU_20240308T100841_B11_20m.jp2\n",
    "│       │   │   ├── [ 23M]  T33UUU_20240308T100841_B12_20m.jp2\n",
    "│       │   │   ├── [ 25M]  T33UUU_20240308T100841_B8A_20m.jp2\n",
    "│       │   │   ├── [2.2M]  T33UUU_20240308T100841_SCL_20m.jp2\n",
    "│       │   │   ├── [ 31M]  T33UUU_20240308T100841_TCI_20m.jp2\n",
    "│       │   │   └── [ 19M]  T33UUU_20240308T100841_WVP_20m.jp2\n",
    "│       │   └── [ 41M]  R60m\n",
    "│       │       ├── [110K]  T33UUU_20240308T100841_AOT_60m.jp2\n",
    "│       │       ├── [2.5M]  T33UUU_20240308T100841_B01_60m.jp2\n",
    "│       │       ├── [2.8M]  T33UUU_20240308T100841_B02_60m.jp2\n",
    "│       │       ├── [2.9M]  T33UUU_20240308T100841_B03_60m.jp2\n",
    "│       │       ├── [3.0M]  T33UUU_20240308T100841_B04_60m.jp2\n",
    "│       │       ├── [3.1M]  T33UUU_20240308T100841_B05_60m.jp2\n",
    "│       │       ├── [3.3M]  T33UUU_20240308T100841_B06_60m.jp2\n",
    "│       │       ├── [3.3M]  T33UUU_20240308T100841_B07_60m.jp2\n",
    "│       │       ├── [3.3M]  T33UUU_20240308T100841_B09_60m.jp2\n",
    "│       │       ├── [3.3M]  T33UUU_20240308T100841_B11_60m.jp2\n",
    "│       │       ├── [3.3M]  T33UUU_20240308T100841_B12_60m.jp2\n",
    "│       │       ├── [3.4M]  T33UUU_20240308T100841_B8A_60m.jp2\n",
    "│       │       ├── [480K]  T33UUU_20240308T100841_SCL_60m.jp2\n",
    "│       │       ├── [3.6M]  T33UUU_20240308T100841_TCI_60m.jp2\n",
    "│       │       └── [2.7M]  T33UUU_20240308T100841_WVP_60m.jp2\n",
    "│       ├── [364K]  MTD_TL.xml\n",
    "│       └── [1.2M]  QI_DATA\n",
    "│           └── ...\n",
    "├── [166K]  HTML\n",
    "│   └── ...\n",
    "├── [ 18K]  INSPIRE.xml\n",
    "├── [ 68K]  manifest.safe\n",
    "├── [ 54K]  MTD_MSIL2A.xml\n",
    "├── [7.3K]  rep_info\n",
    "│   └── ...\n",
    "└── [ 19K]  S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352-ql.jpg\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1bcf5f-194e-4f77-90f6-6484b1b78b63",
   "metadata": {},
   "source": [
    "### Sentinel-2 Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd750eeb-b299-43c5-aec2-d479a47bbba0",
   "metadata": {},
   "source": [
    "| **Band** | **Description**        | **Central Wavelength (nm)** | **Bandwidth (nm)** | **Spatial Resolution** |\n",
    "|----------|------------------------|------------------------------|---------------------|-------------------------|\n",
    "| Band 1   | Coastal aerosol        | 443                          | 20                  | 60 m                    |\n",
    "| Band 2   | **Blue**                   | 490                          | 65                  | 10 m                    |\n",
    "| Band 3   | **Green**                  | 560                          | 35                  | 10 m                    |\n",
    "| Band 4   | **Red**                    | 665                          | 30                  | 10 m                    |\n",
    "| Band 5   | Vegetation Red Edge    | 705                          | 15                  | 20 m                    |\n",
    "| Band 6   | Vegetation Red Edge    | 740                          | 15                  | 20 m                    |\n",
    "| Band 7   | Vegetation Red Edge    | 783                          | 20                  | 20 m                    |\n",
    "| Band 8   | NIR (Near Infrared)    | 842                          | 115                 | 10 m                    |\n",
    "| Band 8A  | Narrow NIR             | 865                          | 20                  | 20 m                    |\n",
    "| Band 9   | Water vapor            | 945                          | 20                  | 60 m                    |\n",
    "| Band 10  | SWIR – Cirrus          | 1375                         | 30                  | 60 m                    |\n",
    "| Band 11  | SWIR                   | 1610                         | 90                  | 20 m                    |\n",
    "| Band 12  | SWIR                   | 2190                         | 180                 | 20 m                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e245632-6fbb-41b9-9558-b2bb9ab4a13d",
   "metadata": {
    "id": "AC4NagonLouP"
   },
   "source": [
    "## Programmatically accessing bands\n",
    "\n",
    "### Test importing Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c4fa4-2cd7-40fd-89f3-2dd49b507d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import requests\n",
    "from tqdm.rich import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347a06c-cc3a-4af1-8930-e322e4c8fd19",
   "metadata": {
    "id": "AC4NagonLouP"
   },
   "source": [
    "If the libraries aren't available, make sure that the correct IPython Kernel is selected!\n",
    "\n",
    "If it is not, change the kernel, e.g., by starting jupyter lab in a different environment!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b37cf0-8fe7-46c0-aaf1-b3bd4ebf4059",
   "metadata": {
    "id": "Zl7It4oWPKRt"
   },
   "source": [
    "### Download the tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171626c-710e-4671-8d46-a0adf23b775e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae0c95-8179-4421-baec-2b3e789abc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "??Path.mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9b25d-b0f8-443b-81ad-e50b3c821245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "# For quick prototyping there is on such things as _too many_ asserts!\n",
    "assert data_path.exists, \"Should exist after calling mkdir!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da525c-6899-493c-91a5-2da584f5548a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_name = Path(\"S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352\")\n",
    "output_filepath = data_path / tile_name.with_suffix(\".SAFE.zip\")\n",
    "output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010e3d9-a277-431b-a19e-41c3082b3793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-hosted file on TUB-Cloud for fast download during class ~800MB before and after unpacking\n",
    "sentinel_tile_url = \"https://tubcloud.tu-berlin.de/s/2EMnZwypF2pK5XG/download/S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352.SAFE.zip\"\n",
    "\n",
    "# Provided template to download file; not relevant for course\n",
    "def download_file_with_progress(url: str, output_file: Path):\n",
    "    \"\"\"\n",
    "    Given a `url` as a String and an `output_file` as a file-path the item will\n",
    "    be downloaded and written to the `output_file`. If the `output_file` already\n",
    "    exists, it will be overwritten.\n",
    "    \"\"\"\n",
    "    s = requests.Session()\n",
    "    chunk_size = 2**20  # mb\n",
    "    with s.get(url, stream=True) as resp:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            print(f\"Saving to {output_file}\")\n",
    "            for data in tqdm(\n",
    "                resp.iter_content(chunk_size=chunk_size), \n",
    "                total=int(resp.headers.get(\"content-length\", 0)) // chunk_size, \n",
    "                unit=\"MB\",\n",
    "                unit_scale=True,\n",
    "                desc=\"Downloading...\",\n",
    "            ):\n",
    "                f.write(data)\n",
    "\n",
    "download_file_with_progress(url=sentinel_tile_url, output_file=output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40a47c-f8a7-49b7-91b7-022172290f31",
   "metadata": {
    "id": "_02CZZ6mPygz"
   },
   "source": [
    "### Extract zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f1cc2-1082-4b6c-b09b-3c3a288f55a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile(output_filepath)\n",
    "zipf.extractall(path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee05ab-a591-4de6-97ba-5e3975cb696e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2726,
     "status": "ok",
     "timestamp": 1618818362347,
     "user": {
      "displayName": "Mat Rb",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gik24jvA_yZMp2z50oFh_gbhSlIRnt_v5WBVKY6REE=s64",
      "userId": "17685210069082378191"
     },
     "user_tz": -120
    },
    "id": "YBKj8TTPYGNU",
    "outputId": "b1d9c5c9-7047-42e9-dc3f-18a12b24fe53",
    "tags": []
   },
   "source": [
    "Take a look at the folder structure on your laptop / notebook file viewer and understand what happened!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64b2d8-23d6-4812-aa80-00a5beefcd2c",
   "metadata": {},
   "source": [
    "The data inside of the Zip-file is packaged into a \"root\" directory with the name of the original zip file without the `.zip` but with `.SAFE` extension.\n",
    "The data we are interested in lives inside a subdirectory called `GRANULE/*/IMG_DATA`.\n",
    "The image data is encoded as a [jpeg2000](https://de.wikipedia.org/wiki/JPEG_2000) file with the extension `jp2`.\n",
    "\n",
    "We can combine all of the information to build a [glob](https://en.wikipedia.org/wiki/Glob_(programming)) expression to quickly build a list of the files we are interested in.\n",
    "\n",
    "Note: The directory structure has changed within the last two years, depending on the selected dates, the relevant images live either directly under the `IMG_DATA` directory, or they live under a sub-directory `IMG_DATA/R{10,20,60}m/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d740160-7a60-4b84-bfdf-f066da3b31b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unzipped_dir = Path(data_path / tile_name.with_suffix(\".SAFE\"))\n",
    "assert unzipped_dir.exists(), f\"{unzipped_dir} does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1503b-4d6d-4f2c-9efe-bc1920719f10",
   "metadata": {},
   "source": [
    "## Working with the tile data\n",
    "### Accessing the data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ff1bf-de5b-471d-92b8-d41349788619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class S2TileReader:\n",
    "    def __init__(self, directory: Path):\n",
    "        \"\"\"\n",
    "        Initialize the reader with a directory containing the SAFE file of a Sentinel-2 product.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory : Path\n",
    "            The directory containing the SAFE file of a Sentinel-2 product.\n",
    "        \"\"\"\n",
    "        assert directory.is_dir(), f\"{directory} is not a directory\"\n",
    "        self.image_files = list(directory.glob(f\"**/IMG_DATA/*.jp2\"))\n",
    "        if len(self.image_files) == 0:\n",
    "            self.image_files = list(directory.glob(f\"**/IMG_DATA/R60m/*.jp2\"))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R20m/*.jp2\")))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R10m/*.jp2\")))\n",
    "        self.band2file_mapping = self._bands()\n",
    "        self.bands = sorted(self.band2file_mapping.keys())\n",
    "        print(f\"{len(self.band2file_mapping)} images found in {directory}\")\n",
    "\n",
    "    def _bands(self):\n",
    "        \"\"\"\n",
    "        Extract the band names from the image files and create a mapping from band name to file path.\n",
    "\n",
    "        Example:\n",
    "        {\n",
    "            \"B01\": Path(\"path/to/B01.jp2\"),\n",
    "            \"B02\": Path(\"path/to/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        or if the product has multiple resolutions:\n",
    "        {\n",
    "            \"B01_60m\": Path(\"path/to/R60m/B01.jp2\"),\n",
    "            \"B02_10m\": Path(\"path/to/R10m/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        return {\"_\".join(x.stem.split(\"_\")[2:]):x for x in self.image_files}\n",
    "\n",
    "    def read_band(self, band: str):\n",
    "        \"\"\"\n",
    "        Read the data of a specific band. The data is returned as a numpy array. If the band is a single channel,\n",
    "        the array will have shape (height, width). If the band is a multi-channel band, the array will have shape\n",
    "        (height, width, channels).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        band : str\n",
    "            The name of the band to read. Must be one of the bands in the product.\n",
    "            Use the `bands` attribute to see the available bands.\n",
    "        \"\"\"\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        with rasterio.open(self.band2file_mapping[band]) as f:\n",
    "            data = f.read()\n",
    "        if data.shape[0] == 1:\n",
    "            return data.squeeze(0)\n",
    "        elif data.shape[0] == 3:\n",
    "            return np.transpose(data, (1, 2, 0))\n",
    "\n",
    "tile = S2TileReader(unzipped_dir)\n",
    "band03_data = tile.read_band(\"B03_60m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e115b2e-79a1-47c0-aaef-e5ad7ebbf9aa",
   "metadata": {},
   "source": [
    "### Visualizing an individual channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2810c74-e75a-4161-bffe-63fbc1672dde",
   "metadata": {},
   "source": [
    "Sentinel-2 satellite data is encoded in an uncommon format `uint16` and requires special care, when trying to visualize.\n",
    "The minimum and maximum values are given by physical properties of the sensor and are not normalize to fill the entire data range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a86cb-cf16-4eaf-b194-209c16b019bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "band03_data.min(), band03_data.max(), band03_data.shape, band03_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c31039-72bf-48a2-9adb-221d07ae491b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(band03_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb67b5-5530-4dfb-a91c-2c8f71ab691b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(band03_data, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e2395-70df-432b-8162-0efe1cf3611b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(band03_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bfd44-deac-4279-a756-6ea9f619b295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quant_norm_data(\n",
    "    data: np.ndarray, lower_quant: float = 0.01, upper_quant: float = 0.99\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the data by quantiles `lower_quant/upper_quant`.\n",
    "    The quantiles are calculated globally/*across all channels*.\n",
    "    \"\"\"\n",
    "    return np.zeros_like(data)\n",
    "\n",
    "\n",
    "# More details follow\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(quant_norm_data(band03_data), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407b80e-3bfc-4c64-ac39-97be1c6bfa92",
   "metadata": {
    "id": "atNCJ50xFrl3"
   },
   "source": [
    "# Working with Sentinel-2 and Copernicus API\n",
    "\n",
    "Goal of the lecture:\n",
    "1. Visualize multiple bands from the downloaded tile\n",
    "1. Create an RGB image of three bands; one true-color and one false-color composite\n",
    "1. Programmatically download the tile from the open and free [Copernicus Dataspace](https://dataspace.copernicus.eu/) page\n",
    "1. Select a sub-region of the tile by defining a region of interest\n",
    "1. Visualize the spectral signature of different land-use/land-cover classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2465873-7c8c-48e7-956d-dbf7826ba234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing multiple bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199306e-f505-4b30-9618-f77e1c55b796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# discussion from last time\n",
    "def quant_norm_data(\n",
    "        data: np.ndarray, lower_quant: float = 0.01, upper_quant: float = 0.99\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the data by quantiles `lower_quant/upper_quant`.\n",
    "    The quantiles are calculated globally/*across all channels*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        The data to normalize.\n",
    "    lower_quant : float\n",
    "        The lower quantile. Default is 0.01.\n",
    "    upper_quant : float\n",
    "        The upper quantile. Default is 0.99.\n",
    "    \"\"\"\n",
    "    masked_data = np.ma.masked_equal(data, 0)\n",
    "    lq, uq = np.quantile(masked_data.compressed(), (lower_quant, upper_quant))\n",
    "    data = np.clip(data, a_min=lq, a_max=uq)\n",
    "    data = (data - lq) / (uq - lq)\n",
    "    return data\n",
    "\n",
    "\n",
    "def vis(data: np.ndarray, quant_norm: bool = False):\n",
    "    \"\"\"\n",
    "    Visualize an array by calling `imshow` with `cmap=\"gray\"` for 1 channel inputs and no cmap for 3 channel inputs.\n",
    "    Expected shape is either (H, W) or (H, W, 3) for 1 and 3 channel inputs respectively. Assumes RGB order for 3\n",
    "    channel inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        The data to visualize. Expected shape is either (H, W) or (H, W, 3) for 1 and 3 channel inputs respectively.\n",
    "        Assumes RGB order for 3 channel inputs.\n",
    "    quant_norm : bool\n",
    "        Whether to quantile normalize the data. Default is False.\n",
    "    \"\"\"\n",
    "    if quant_norm:\n",
    "        data = quant_norm_data(data)\n",
    "    if data.ndim == 2:\n",
    "        plt.imshow(data, cmap=\"gray\")\n",
    "    elif data.ndim == 3:\n",
    "        plt.imshow(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected data to have 2 or 3 dimensions, but got {data.ndim} dimensions.\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ecc83-6ec1-4c06-b382-d672aaeca840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_reader = S2TileReader(unzipped_dir)\n",
    "s2_reader.bands\n",
    "\n",
    "rgb_arr = np.stack(\n",
    "    [s2_reader.read_band(b) for b in (\"B04_60m\", \"B03_60m\", \"B02_60m\")],\n",
    "    axis=-1,\n",
    ")\n",
    "rgb_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f1e9a-a027-453c-b501-970dbef008c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For 3-dimensional input,\n",
    "# matplotlib's plot function does NOT imply a min-max-normalization!\n",
    "vis(rgb_arr, quant_norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379394e7-292e-4830-bd69-71b615b6502b",
   "metadata": {},
   "source": [
    "Our _quantile normalizaiton_ strategy, provides very good visual results without too much hand-tuning required.\n",
    "\n",
    "But beware of the difference between our underlying *data* and the\n",
    "visual interpretation! They are not the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43294ddc-c007-4275-a65a-ef32e93910a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis(rgb_arr, quant_norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd06d8e-1555-4ea6-951d-caafb321f5cb",
   "metadata": {},
   "source": [
    "### Course exercise\n",
    "\n",
    "Create a [False Color Composite](https://en.wikipedia.org/wiki/False_color) by visualizing the bands `B8A`, `B04`, `B03`.\n",
    "Try not use the `vis` function. If you have additional time, see what happens if you apply a _manual min-max_ normalization instead!\n",
    "\n",
    "Note: We will talk about the meaning and application of false color composites in the future. For now, the goal is to familiarize yourself with `numpy`, matrix-operations, and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44daa1fb-aaff-40f3-a061-c50da7f1232c",
   "metadata": {},
   "source": [
    "## Copernicus API\n",
    "\n",
    "Take a look at [Copernicus Dataspace](https://dataspace.copernicus.eu/) and make sure you have created an account and have the correct log-in data available. If you haven't already:\n",
    "1. Sign up for the service \n",
    "2. Confirm the registration e-mail\n",
    "\n",
    "In the following section, we will access the service over its [API](https://en.wikipedia.org/wiki/API)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa47a3-3dfc-46d0-8865-2a1caec5bd2d",
   "metadata": {},
   "source": [
    "To view the different tile data we don't need the access token, but to later download a tile, we need it. \n",
    "The token is valid for only 1 hour, so we cannot reuse it between sessions and have to create it new each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec769ed-fdf2-4b1e-81d1-0c02b8f51d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the access token for the Copernicus Data Store. This token is required to access the data for download.\n",
    "    The token is not required for querying the data. It is valid for 3600 seconds (1 hour).\n",
    "\n",
    "    ----------\n",
    "    username : str\n",
    "        The username for the Copernicus Data Store.\n",
    "    password : str\n",
    "        The password for the Copernicus Data Store.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"grant_type\": \"password\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "            data=data,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Access token creation failed. Response from the server was: {r.json()}\"\n",
    "        )\n",
    "    return r.json()[\"access_token\"]\n",
    "\n",
    "# you may enter the credentials directly in your notebook\n",
    "user_name = \"\"\n",
    "password = \"\"\n",
    "\n",
    "# the following code is for us to not have to share our secrets ;)\n",
    "user_p = Path(\"user.txt\")\n",
    "pwd_p = Path(\"secret.txt\")\n",
    "if user_p.exists():\n",
    "    user_name = user_p.read_text(encoding='utf-8').strip()\n",
    "if pwd_p.exists():\n",
    "    password = pwd_p.read_text(encoding='utf-8').strip()\n",
    "\n",
    "assert user_name != \"\", \"Please provide your user-name!\"\n",
    "assert password != \"\", \"Please provide your password!\"\n",
    "\n",
    "# return the access token\n",
    "access_token = get_access_token(user_name, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fabbad-59b3-476f-9990-2cb0b72f5d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, Iterable, Tuple\n",
    "\n",
    "def dataspace_dataframe_from_attributes(\n",
    "    collection: str = \"SENTINEL-2\",\n",
    "    aoi: Optional[str] = None,\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    attributes: Optional[Iterable[Tuple[str, str, float]]] = None,\n",
    "    max_returned_items: int = 20\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a dataframe of items from the Copernicus DataSpace API based on the given attributes.\n",
    "    The request is build based on the OData standard as documented at\n",
    "    https://documentation.dataspace.copernicus.eu/APIs/OData.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : str\n",
    "        The collection to search for. Default is \"SENTINEL-2\".\n",
    "    aoi : str, optional\n",
    "        The area of interest in WKT format. Default is None.\n",
    "    start_date : str, optional\n",
    "        The start date in the format \"YYYY-MM-DD\". Default is None.\n",
    "    end_date : str, optional\n",
    "        The end date in the format \"YYYY-MM-DD\". Default is None.\n",
    "    attributes : Iterable[Tuple[str, str, float]], optional\n",
    "        The attributes to filter by. Default is None which means no filtering and is equivalent to an empty list.\n",
    "        Each tuple should be in the format (key, comparison, value).\n",
    "        The comparison should be one of \"lt\", \"le\", \"eq\", \"ge\", \"gt\".\n",
    "        Currently only attributes of type double and that are comparable are supported.\n",
    "    max_returned_items : int, optional\n",
    "        The maximum number of items to return. Default is 20. Must be in [0, 1000].\n",
    "    \"\"\"\n",
    "    if attributes is None:\n",
    "        attributes = []\n",
    "    request_str = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=\"\n",
    "    request_str += f\"Collection/Name eq '{collection}'\"\n",
    "    if aoi is not None:\n",
    "        request_str += f\" and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}')\"\n",
    "    if start_date is not None:\n",
    "        request_str += f\" and ContentDate/Start gt {start_date}T00:00:00.000Z\"\n",
    "    if end_date is not None:\n",
    "        request_str += f\" and ContentDate/Start lt {end_date}T00:00:00.000Z\"\n",
    "    for k, comp, v in attributes:\n",
    "        assert comp in [\"lt\", \"le\", \"eq\", \"ge\", \"gt\"]\n",
    "        request_str += f\" and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq '{k}' and att/OData.CSC.DoubleAttribute/Value {comp} {v:.2f})\"\n",
    "    # get all attributes\n",
    "    request_str += \"&$expand=Attributes\"\n",
    "    # get top n items\n",
    "    assert 0 <= max_returned_items <= 1000, f\"Copernicus API only allows returned items in [0, 1000], but {max_returned_items} is outside this range.\"\n",
    "    request_str += f\"&$top={max_returned_items}\"\n",
    "    json_result = requests.get(request_str).json()\n",
    "    json_vals = json_result['value']\n",
    "    return pd.DataFrame.from_dict(json_result['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4d941-fa3b-4247-af8d-7b29615e3a26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's see what this function does\n",
    "?dataspace_dataframe_from_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3db0d-64bc-4aa5-89fc-3c821b0ed57f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataspace_dataframe_from_attributes(attributes=[('cloudCover', 'le', 40)], max_returned_items=1)['Attributes'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76b9a4-47ee-4ace-8559-a1018c3abaa9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataspace_dataframe_from_attributes()['Attributes'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b5f67-4f97-4ab8-973e-85d889250c9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "We can see that key-word arguments and attributes can be provided. The attributes are filtered server-side. Right now, only attributes of type double are supported. To see the attributes of a certain product, you have to look into the `'Attributes'`-column of the respective data frame. Not all products have all attributes assigned.\n",
    "\n",
    "To access a range for an attribute, two values have to be inserted, once with upper and once with lower bound\n",
    "\n",
    "### Course exercise\n",
    "Given the available information, construct a query that has the following properties:\n",
    "- Start date is `2023-10-30` and end date is `2023-10-31`\n",
    "- Cloud coverage is between 1.5 and 2.2\n",
    "- Satellite Platform: `SENTINEL-2`\n",
    "\n",
    "You should get back 609 query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00692c5e-fe67-4c46-98b5-4e4e92e9a8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "products = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611323b3-c1eb-4c65-8cb6-99e7e32a2ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(products) == 609, f\"Expected 609 results, got {len(products)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10204f-393e-49d3-8d76-44c0024df909",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797bdb09-8e0c-4fc5-94ad-d53cf486a8b8",
   "metadata": {},
   "source": [
    "To make it easier to work with the data, we will transform it from a [pandas](https://pandas.pydata.org/) [DataFrame](https://pandas.pydata.org/docs/user_guide/index.html), into a DataFrame that is aware of geographical meta-data and shapes, [geopandas](https://geopandas.org/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ae317-37c6-41bd-a63c-eddfbe8e75b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def copernicus_df_to_gdf(copernicus_df: pd.DataFrame, strftime: Optional[str] = None) -> gpd.GeoDataFrame:\n",
    "    if strftime is not None and strftime.lower() in ['iso', 'iso 8601', 'default']:\n",
    "        strftime = '%Y-%m-%dT%H:%M:%S'\n",
    "    df = copernicus_df.copy()\n",
    "    # split footprint into geometry (wkt text) and crs\n",
    "    # assign crs\n",
    "    crss = df['Footprint'].apply(lambda x: \"EPSG:\"+x.split(';')[0].split(\"'\")[1].split('=')[1])\n",
    "    assert len(crss.unique()) == 1, \"Multiple CRS values in data frame, geopandas can't handle that.\"\n",
    "    # assign geometry\n",
    "    df['geometry'] = gpd.GeoSeries.from_wkt(df['Footprint'].apply(lambda x: x.split(';')[1].split(\"'\")[0]), crs=crss.iloc[0])\n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "    attribute_names = set(sl['Name'] for l in gdf['Attributes'] for sl in l)\n",
    "    ignored_date_conversions = []\n",
    "    successful_date_conversions = []\n",
    "    for attr in attribute_names:\n",
    "        gdf[attr] = gdf['Attributes'].apply(lambda x: [i for i in x if i['Name'] == attr][0]['Value'] if len([i for i in x if i['Name'] == attr]) > 0 else np.nan)\n",
    "    for attr in gdf.columns:\n",
    "        if 'Date' in attr:\n",
    "            # convert to DateTime\n",
    "            try:\n",
    "                gdf[attr] = pd.to_datetime(gdf[attr], yearfirst=True, format='mixed')\n",
    "                # convert to numeric or string to make it json-serializable\n",
    "                if strftime is None:\n",
    "                    gdf[attr] = gdf[attr].values.astype(np.int64) // 10 ** 9\n",
    "                else:\n",
    "                    gdf[attr] = gdf[attr].dt.strftime(strftime)\n",
    "            except Exception as e:\n",
    "                ignored_date_conversions += [attr]\n",
    "                continue\n",
    "            successful_date_conversions += [attr]\n",
    "    print(f\"Ignored date conversions: {ignored_date_conversions}\")\n",
    "    print(f\"Successful date conversions: {successful_date_conversions}\")\n",
    "    return gdf\n",
    "    \n",
    "gdf = copernicus_df_to_gdf(products, strftime='ISO')\n",
    "gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deb13a-2eec-4866-9fa4-770e509152fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to only display the first 2\n",
    "gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63046b5a-2d51-4b71-a808-cdf3dcd7ecdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a subset of the columns for clarity; these are way too many\n",
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209f2a4-77ca-41b6-ad47-4a205e1ee914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_gdf = gdf[[\"Name\", \"Id\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbff51-4c11-4b9a-bbe5-35e25c29ffe1",
   "metadata": {},
   "source": [
    "### Geopandas\n",
    "\n",
    "When you have a `GeoDataFrame` with a `geometry` column set (as provided by the `SentinelAPI`) you can quickly visualize your geographical data. This is one of the main benefits why we use `GeoDataFrame` over a simple Pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5eda6d-ed00-460a-ae11-5332d14b97bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_gdf.head(5).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ef87a-0756-444d-b61b-e86ddb038719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_gdf.head(1).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37008971-834f-482a-a59a-9e1fab700985",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Geopandas in short\n",
    "\n",
    "A [GeoDataFrame](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.html#geopandas.GeoDataFrame) contains one special column and one _special_ property.\n",
    "The _geometry_ column and the [CRS](https://en.wikipedia.org/wiki/Spatial_reference_system) column.\n",
    "\n",
    "##### Geometries/Shapes\n",
    "\n",
    "The geometry column contains _shapes_ in reference to [Coordinate Reference System](https://en.wikipedia.org/wiki/Spatial_reference_system).\n",
    "Let's look at the geometry columns first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a8782-564d-4cad-8b8b-bb824f858f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# by default it does some nice plotting\n",
    "geometry = sub_gdf.iloc[0][\"geometry\"]\n",
    "geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de00a0-9bdd-4b22-8a5d-4a1d1c93c405",
   "metadata": {},
   "source": [
    "How is the data structure represented?\n",
    "\n",
    "Simply by defining the type of shape (here `POLYGON` or `MultiPolygon`) and the X-Y coordinates of each point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df40d24-3a24-4295-8d57-41349fee56c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(geometry.wkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916ca90-adf8-4d75-a2a7-ca2ec704cc47",
   "metadata": {},
   "source": [
    "Similar to [JSON](https://en.wikipedia.org/wiki/JSON) these shapes/geometries have their own file format(s) that are used to serialize/deserialize the data, called [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) (Well-known text representation of geometry).\n",
    "The exact structure of the data format is not too important (nor their alternatives), the main thing to remember is that geometries may be defined by simple textual description, such as `POINT (30 10)` or `LINESTRING (30 10, 10 30, 40 40)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e1df9-5db3-4542-b3e1-a2bdfe16e561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "point = geometry.representative_point()\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a3255-e190-4f3b-bfaa-d756e96ae94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "point.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e3e47-b3ae-4357-a72a-bc9fe9b85d59",
   "metadata": {},
   "source": [
    "##### Coordinate Reference System\n",
    "\n",
    "Now let's take a quick look at the [Coordinate Reference System](https://en.wikipedia.org/wiki/Spatial_reference_system).\n",
    "Confusingly, a popular format that is used to describe the coordinate reference system, is also called [WKT or WKT-CRS](https://en.wikipedia.org/wiki/Well-known_text_representation_of_coordinate_reference_systems) (Well-known text representation of coordinate reference systems):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20e116-d496-4ff9-a989-cd8ed3af48f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sub_gdf.crs.to_wkt(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a839a-e9e0-4abd-a471-ca9cf3347819",
   "metadata": {},
   "source": [
    "Most coordinate reference systems can also be encoded as an [EPSG code](https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset) which is a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91325571-f21c-49c5-b5ac-6702a8f874eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_gdf.crs.to_epsg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275553a-ccb3-4dcd-8c90-d83d01303154",
   "metadata": {},
   "source": [
    "Again, it is not important to understand the data format in detail!\n",
    "The main thing to remember is that in order to specify _any_ point in space, we not only need the coordinates but also information to what our axis/scale relate to.\n",
    "For our use-cases the main number to remember is the EPSG code *4326* which is used to describe (Long, Lat) points on earth. \n",
    "\n",
    "#### Using GeoPandas with Copernicus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cfdb1-847e-4b13-a613-08f7ab93cef0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1960,
     "status": "ok",
     "timestamp": 1618818334836,
     "user": {
      "displayName": "Mat Rb",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gik24jvA_yZMp2z50oFh_gbhSlIRnt_v5WBVKY6REE=s64",
      "userId": "17685210069082378191"
     },
     "user_tz": -120
    },
    "id": "-wm7ZCBvHUCZ",
    "outputId": "8d26a7ec-8d09-40ae-b57d-b2b1741de1e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "\n",
    "from typing import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16657ed8-0098-426f-9828-b94735a21653",
   "metadata": {},
   "source": [
    "Let's select a point of interest (POI).\n",
    "For this lab we will use the TU Berlin building.\n",
    "\n",
    "The following code requires the Latitude and Longitude coordinates of the POI.\n",
    "For now, we can simply rely on a service like [LatLong.net](latlong.net) to look up the coordinates:\n",
    "\n",
    "- [TU Berlin coordinates via LatLong.net](https://www.latlong.net/place/technical-university-of-berlin-germany-248.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4259b-815f-441a-8420-aec298642155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latitude = 52.51388\n",
    "longitude = 13.32593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b90480-02f5-4e1b-88e6-1d70b0e094b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a GeoSeries is just one data column of a GeoDataFrame\n",
    "# or you can think of it as a series/list of geographical objects and a CRS\n",
    "?geopandas.GeoSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55211d3-df06-4746-9d21-f66d988a582b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = geopandas.GeoSeries([Point(longitude, latitude)], crs=\"EPSG:4326\")\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583bfab-4fb3-444e-8107-a1c254b64867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GeoPandas allows us to very quickly visually inspect our geographical data\n",
    "series.explore(marker_type=\"marker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865059d-4acc-46a3-a4b7-da4a5ec5f4fa",
   "metadata": {},
   "source": [
    "To query the copernicus database, we need to encode our geometry data into a common format that the service can understand.\n",
    "Looking at the documentation of the query function, we can see that the API expect the data to be encoded as a WKT string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e46d0f-0d47-4b44-b7c9-6f72dfb01b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series.to_wkt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ba9f3-74ed-470e-9fe2-d9e360f7ec0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poi = series.to_wkt()[0]\n",
    "poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d9bb7-e111-413f-9f1c-cef5ccc844c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = date(year=2024, month=3, day=7)\n",
    "end_date = date(year=2024, month=3, day=9)\n",
    "satellite = \"SENTINEL-2\"\n",
    "\n",
    "products = dataspace_dataframe_from_attributes(\n",
    "    collection=satellite,\n",
    "    start_date=start_date.strftime(\"%Y-%m-%d\"),\n",
    "    end_date=end_date.strftime(\"%Y-%m-%d\"),\n",
    "    aoi=poi,\n",
    "    attributes=[('cloudCover', 'le', 40)]\n",
    ")\n",
    "\n",
    "# convert to GeoPandas GeoDataFrame\n",
    "products_gdf = copernicus_df_to_gdf(products, strftime='iso')\n",
    "assert not products_gdf.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ad9bd-8cb0-41a6-bafc-6782a52263e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort and select the first row\n",
    "product = products_gdf.sort_values(\n",
    "    [\"cloudCover\", \"PublicationDate\"], ascending=[True, True]\n",
    ").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f70de-8c81-407f-a501-228baf9b3e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensuring that the tile is the one we are also providing via a direct\n",
    "# download link\n",
    "expected_name = \"S2A_MSIL1C_20240308T100841_N0510_R022_T32UQD_20240308T120958.SAFE\"\n",
    "assert product[\"Name\"].iloc[0] == expected_name, f\"Expected name: {expected_name}, but got name: {product['Name'].iloc[0]}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca2c90-fa77-4d39-92e3-2828d773a425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Would fail, because there are entries that cannot be JSON encoded!\n",
    "# product.explore()\n",
    "# Only visualize the relevant columns and convert them if necessary, for us 'title', 'summary', and 'geometry' are sufficent\n",
    "# if you exclude the geometry column, it cannot be drawn on the map!\n",
    "product[[\"Name\", \"cloudCover\", \"geometry\", 'OriginDate']].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b8ed2-d996-4b13-bb7c-625790599ed9",
   "metadata": {},
   "source": [
    "**Question**: Why does our tile look so oddly shaped? What does it mean? How is our data formatted? Does the _missing/invalid_ region have specific values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabf66d-b8c8-499e-85b7-f9934aa024ea",
   "metadata": {},
   "source": [
    "### Selecting regions of tiles \n",
    "\n",
    "We can use the `osmnx` library to retrieve the area of interest by looking up a name-identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bfd5d4-d949-4368-b94e-8dc4d2bbc0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import osmnx\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a870db-a9bd-49a5-92e8-2f056977c315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "berlin_char_gdf = osmnx.geocode_to_gdf(\"Berlin, Charlottenburg\")\n",
    "berlin_char_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1f5ce-66f3-4140-bfd4-cf65d2b0be98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "berlin_char_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c84a4a-82e0-4f4b-bdb6-6cef1beb824b",
   "metadata": {},
   "source": [
    "From this shape, we can create the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222627f0-b641-4fb0-9544-52b51498b51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "berlin_char_gdf_rect = berlin_char_gdf.envelope\n",
    "berlin_char_gdf_rect.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff823d1-0bcf-420b-b5e5-e502731a7fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?rasterio.mask.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce6808-bfac-4f6c-b310-dd4275b9012a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_s2_jp2_data_with_clipping(\n",
    "    band_data_path: Path, clip_geoseries: geopandas.GeoSeries, envelope: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given the `band_data_path` to a JP2000 encoded GeoTIFF file, return those parts that are overlapping with the\n",
    "    `clip_geoseries` GeoSeries. By default, the bounding box (`envelope`) of the geometry will be used to define the\n",
    "    region of interest.\n",
    "    \"\"\"\n",
    "    # open the GeoTIFF file which also contains the CRS metadata\n",
    "    with rasterio.open(band_data_path) as data:\n",
    "        # ensure that the data is using the same coordinate reference system and reproject if they don't\n",
    "        reprojected_geoseries = clip_geoseries.to_crs(data.crs)\n",
    "        # use the bounding box if `envelope` is set => Make sure that the matrix we get back can contain\n",
    "        # only valid values\n",
    "        reprojected_geoseries = (\n",
    "            reprojected_geoseries.envelope if envelope else reprojected_geoseries\n",
    "        )\n",
    "        # Use crop to only return the matrix that contains our region of interest\n",
    "        # Use `all_touched=True` to make sure that the border is also conisdered \"inside\" the region of interest\n",
    "        out_img, _out_transform = rasterio.mask.mask(\n",
    "            data, reprojected_geoseries, crop=True, all_touched=True\n",
    "        )\n",
    "        # drop singleton axes\n",
    "        out_img = out_img.squeeze()\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0b29c2-42cb-4bd0-85b2-56947e3d9f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class S2TileReader:\n",
    "    def __init__(self, directory: Path):\n",
    "        \"\"\"\n",
    "        Initialize the reader with a directory containing the SAFE file of a Sentinel-2 product.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory : Path\n",
    "            The directory containing the SAFE file of a Sentinel-2 product.\n",
    "        \"\"\"\n",
    "        assert directory.is_dir(), f\"{directory} is not a directory\"\n",
    "        self.image_files = list(directory.glob(f\"**/IMG_DATA/*.jp2\"))\n",
    "        if len(self.image_files) == 0:\n",
    "            self.image_files = list(directory.glob(f\"**/IMG_DATA/R60m/*.jp2\"))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R20m/*.jp2\")))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R10m/*.jp2\")))\n",
    "        self.band2file_mapping = self._bands()\n",
    "        self.bands = sorted(self.band2file_mapping.keys())\n",
    "        print(f\"{len(self.band2file_mapping)} images found in {directory}\")\n",
    "\n",
    "    def _bands(self):\n",
    "        \"\"\"\n",
    "        Extract the band names from the image files and create a mapping from band name to file path.\n",
    "\n",
    "        Example:\n",
    "        {\n",
    "            \"B01\": Path(\"path/to/B01.jp2\"),\n",
    "            \"B02\": Path(\"path/to/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        or if the product has multiple resolutions:\n",
    "        {\n",
    "            \"B01_60m\": Path(\"path/to/R60m/B01.jp2\"),\n",
    "            \"B02_10m\": Path(\"path/to/R10m/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        return {\"_\".join(x.stem.split(\"_\")[2:]):x for x in self.image_files}\n",
    "\n",
    "    def read_band(self, band: str):\n",
    "        \"\"\"\n",
    "        Read the data of a specific band. The data is returned as a numpy array. If the band is a single channel,\n",
    "        the array will have shape (height, width). If the band is a multi-channel band, the array will have shape\n",
    "        (height, width, channels).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        band : str\n",
    "            The name of the band to read. Must be one of the bands in the product.\n",
    "            Use the `bands` attribute to see the available bands.\n",
    "        \"\"\"\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        with rasterio.open(self.band2file_mapping[band]) as f:\n",
    "            data = f.read()\n",
    "        if data.shape[0] == 1:\n",
    "            return data.squeeze(0)\n",
    "        elif data.shape[0] == 3:\n",
    "            return np.transpose(data, (1, 2, 0))\n",
    "\n",
    "    ###\n",
    "\n",
    "    # Add new reading band with clipping function\n",
    "    def read_band_data_with_clipping(\n",
    "        self, band: str, clip_geoseries: geopandas.GeoSeries, envelope: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        return read_s2_jp2_data_with_clipping(img_path, clip_geoseries, envelope=envelope)\n",
    "\n",
    "\n",
    "# re-initialize\n",
    "s2_reader = S2TileReader(unzipped_dir)\n",
    "band03_data = s2_reader.read_band(\"B03_10m\")\n",
    "band03_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a3a0b-8d38-484d-bed1-d9717851d77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clipped_band03_data = s2_reader.read_band_data_with_clipping(\n",
    "    \"B03_10m\", berlin_char_gdf.geometry, envelope=True\n",
    ")\n",
    "clipped_band03_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6117c07-69ab-432d-8726-0f3210c1a1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clipped_rgb_arr = np.stack(\n",
    "    [\n",
    "        s2_reader.read_band_data_with_clipping(b, berlin_char_gdf.geometry)\n",
    "        for b in (\"B04_10m\", \"B03_10m\", \"B02_10m\")\n",
    "    ],\n",
    "    axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94938bb-4141-4be2-a99b-0af135b4e3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis(clipped_rgb_arr, quant_norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8907e8c-94b6-4bdc-a272-daf9968ffe83",
   "metadata": {
    "id": "0KGPyLgKnIPv"
   },
   "source": [
    "## Inspecting spectral signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bf769-2cca-4812-9262-4c69dcc23bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LCLU: Land-Cover Land-Use\n",
    "lclu_gdf = geopandas.GeoDataFrame(\n",
    "    {\"type\": [\"water\", \"airport\", \"forest\"]},\n",
    "    geometry=[\n",
    "        # Took the points from latlong.net\n",
    "        Point(13.175955, 52.456009),\n",
    "        Point(13.508517, 52.380236),\n",
    "        Point(13.212926, 52.478834),\n",
    "    ],\n",
    "    crs=\"epsg:4326\",\n",
    ")\n",
    "lclu_gdf.reset_index().explore(marker_type=\"marker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597084b-9b0c-4297-b692-9af2c0cc1a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# depends on product type and used image directory!\n",
    "AVAILABLE_BANDS = (\n",
    "    \"B01_20m\",\n",
    "    \"B02_10m\",\n",
    "    \"B03_10m\",\n",
    "    \"B04_10m\",\n",
    "    \"B05_60m\",\n",
    "    \"B06_20m\",\n",
    "    \"B07_20m\",\n",
    "    \"B08_10m\",\n",
    "    \"B09_60m\",\n",
    "    \"B11_20m\",\n",
    "    \"B12_20m\",\n",
    "    \"B8A_20m\",\n",
    ")\n",
    "\n",
    "\n",
    "def read_points_from_tile(\n",
    "    s2_reader: S2TileReader,\n",
    "    points_series: geopandas.GeoSeries,\n",
    "    bands: Sequence[str] = AVAILABLE_BANDS,\n",
    ") -> np.ndarray:\n",
    "    if set(lclu_gdf.geom_type) != {\"Point\"}:\n",
    "        raise ValueError(\"Only point geometries are allowed!\")\n",
    "\n",
    "    return np.array([s2_reader.read_band_data_with_clipping(b, points_series) for b in bands])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc64d89-4386-4c97-825e-d0f762941b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lclu_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf7a31-d95c-4803-892e-8a545a6e6b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example of pandas `query` command\n",
    "water_spectral_sig = read_points_from_tile(s2_reader, lclu_gdf.query(\"type == 'water'\"))\n",
    "airport_spectral_sig = read_points_from_tile(\n",
    "    s2_reader, lclu_gdf.query(\"type == 'airport'\").geometry\n",
    ")\n",
    "forest_spectral_sig = read_points_from_tile(s2_reader, lclu_gdf.query(\"type == 'forest'\").geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39294a5-d23c-4186-beca-85c2785fe713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following figure takes a very naïve approach and assumes that the selected pixels are noise free, high-resolution, etc.\n",
    "# but it is sufficient to get a clear understanding of general form of different spectral reflectance curves.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(AVAILABLE_BANDS, forest_spectral_sig, \"o-\", label=\"forest\", linewidth=2, color=\"green\")\n",
    "plt.plot(AVAILABLE_BANDS, airport_spectral_sig, \"o-\", label=\"airport\", linewidth=2, color=\"gray\")\n",
    "plt.plot(AVAILABLE_BANDS, water_spectral_sig, \"o-\", label=\"water\", linewidth=2, color=\"blue\")\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99fd81-38d0-4a58-a914-92d69a2588f7",
   "metadata": {
    "id": "brg-cl6PETK-"
   },
   "source": [
    "### Course exercise\n",
    "\n",
    "Select 3 different point (pixels) and plot their spectral signitures.\n",
    "Select those points either by using [LatLong.net](latlong.net) or using the `osmx` library and applying the correct function to the geometries to get a `Point`.\n",
    "\n",
    "Feel free to play around with the variuous different GeoDataFrame functions as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
